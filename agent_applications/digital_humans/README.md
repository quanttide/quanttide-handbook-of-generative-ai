# 数字人
目前主要功能是对话，其中情感识别是一个主要问题。
在市面上的模型中，Hume AI 可以识别语音中的情绪变化，如是否开心。从直观来说，这会使对话更有情绪，更像真人。此类添加了情感的AI会更能调动用户聊天的热情，创造有温度的对话，在如情感陪护之类的2C市场有十分广阔的前景。
如果不试图解决情感识别问题，对接知识库也可以在一定程度上满足当前应用的需求。此类数字人可通过在本地自建知识库，然后对接语音生成平台（如讯飞API，或者部署语音生成的模型）初步实现。
当前数字人在外貌和行为动作上不完善，与真人差距较大，没有表情
数字人的技术线：
1.数字分身，基于AI视频生产的数字人，和人非常相似，长期使用需要一直付费，不能算标准的数字分身，其实是2D的图片动起来，固定肢体动作来动，或没有肢体动作。用深度学习识别出人的五官，结合TTS，让他的五官以一定的情感姿态、更像真人表达。情绪依据上传的模板。通过识别出一个平面的骨骼结构，去做动作捕捉，包括面部表情的捕捉
2.数字人，在游戏引擎里面去创作一个角色，这个角色根据你的诉求来讲话运动，已经很成熟了。卡通数字人，对接知识库，技术相对比较成熟，已经到了天花板，不需要很大的计算资源，元宇宙相关。贴合本地的产业化，单独定制开发，它本质上还是游戏一样NPC，和其他技术成熟度的形态不一样，导致他们的商业模式不同。买断制，在动作上更加完善

数字分身这个平台其实更像是一个SaaS平台。这些功能都作为一个月费面向C端用户，这个技术还不能算是成熟，还在发展。
主体平台都是在国外。
因为以上两个原因，在国内很难本地化做部署。
联通这样的大企业，如果要用数字人的话，出于一些考虑要本地部署。这需要大量的算力资源。如果仅仅做一个项目例如客服的话，这个商业资源可能这个企业也很难承担得起，因为一次性消耗性价比低。
没有特别多2D还是3D的数字人和知识库、TTS结合在一起的平台，至少还没有看到平台，把这些东西全串起来，变成一个完整的工作流。
from：心灵远行、张一川、石祥仁
